## Pre-processing through fMRIprep

1. In DiscoveryOOD, open the work/mindlab/NUBIC/THAMP_Study folder


2. Check data for duplicates (work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code)
- Change the directory & output for all py code files: 
  - Define the top-level directory path (top_level_directory = '/work/mindlab/NUBIC/THAMP_Study/dicom_to_run')
  - Define the log file path (log_file_path = '/work/mindlab/NUBIC/THAMP_Study/dicom_cleanup.log')

In terminal, while in the code folder, run:
	srun --pty /bin/bash
	module load anaconda3/2022.05

- Check functional maps:
	python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/check_fmap.py

- Clean anatomical files:
	python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/clean_anat.py

- Check functional files (sart, 2back, rest):
  	python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/check_sartfunc.py
  	python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/check_2backfunc.py
  	python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/check_restfunc.py

3. Pre-Dicom to Bids Conversion
- Check that each particpant folder is correct in the directory /work/mindlab/NUBIC/THAMP_Study/dicom/Thamp_YYMMDDFLLL/Loui_Laats_1031_Thamp-1. Each participant should have the following:
	- 6 field map folders (fmaps); there should be 3 folders with _dirPA_ and 3 folders with _dirAP_
	- 8 functional folders (funcs; taskrest, tasktestVol, taskthamp2back, taskthampsart); each individual task should have 2 respective folders
- Check for duplicates
	- Check number at the end of the folder
	- This number indicates the sequence order of scans
	- If there is a duplicate, check both folders to see if one is empty/blank
	- Remove any blank folders and mark which participants had duplicates


4. Dicom to Bids Conversion
- Change wang.jinyu2 in line 29 of /work/mindlab/NUBIC/THAMP_Study/BIDS/dcm2bids_slurm.sh to the data (updated username/data path)
- Ensure that the source reads "source activate my_dcm2bids_env"
- Ensure that the dicom directory = /work/mindlab/NUBIC/THAMP_Study/dicom_to_run
- Run in terminal:
  	cd /work/mindlab/NUBIC/THAMP_Study/BIDS
  	sbatch dcm2bids_slurm.sh


5. Removing the prefix: bids:sub-xxxxxxx
In terminal, again while in the code folder, before running python, run:
	srun --pty /bin/bash
	module load anaconda3/2022.05
  python /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc/code/update_intendedfor.py
- Ensure that the base directory = /work/mindlab/NUBIC/THAMP_Study/BIDS


6. Batch Run fMRIprep
After Python, in terminal run:
	cd /work/mindlab/NUBIC/THAMP_Study/fmriprep_preproc
	sbatch fmriprep_run_parallel.sh
- All participants should now have a unique folder in the directory /work/mindlab/NUBIC/THAMP_Study/BIDS/derivatives/fmriprep
- Each folder should contain 4 sub-folders (anat, figures, func, log)

## Pre 1st level anaylsis prep

1. In DiscoveryOOD, open the work/mindlab/NUBIC/THAMP_Study/BIDS/derivatives/fmriprep folder


2. Select a participant folder (sub-YYMMDDFLLL) and open their "func" folder


3. Within this folder, open the terminal and run:
	gunzip *.nii.gz
- This will unzip all functional task files including all resting state tasks and both behavioral tasks


4. Open the directory /work/mindlab/Projects/THAMP/fMRIprepped
- This contains all participant data that has been through 1st and 2nd level analysis
- Each participant should have a unique folder (YYMMDDFLLL_1lvl) with 2 sub folders (slices and spm)
- The Slices folder should contain 2 sub folders (WM and SART) which respectively contain the sliced (sub), realigned (rsub), and smoothed (srsub) images
	- Each participant should have 768 sliced files after loading into SPM
	- After realigning and smoothing, each participant should have 2304 files (768 sub, 768 rsub, and 768 srsub)
- The SPM folder should contain the SPM.mat file
	- Each contrast is also noted in this folder with the contrasts being set-up as so:
		con_0001.nii = SART mod>unmod
		con_0002.nii = 2-BACK mod>unmod
		con_0003.nii = SART>2-BACK
		con_0004.nii = mod>unmod
		con_0005.nii = mod
		con_0006.nii = unmod
		con_0007.nii = unmod>mod
		con_0008.nii = 2-BACK>SART
	- The beta files should correspond to the contrasts designed in the 1st level analysis


## 1st Level Analysis

1. In DiscoveryOOD, open the work/mindlab/NUBIC/THAMP_Study/BIDS/derivatives/fmriprep folder

2. Also in DiscoveryOOD, start a MATLAB session
- For the paramters, I would give as much time as needed depending on your intended session length, 6-8 GPUs, and 3-6 GB of memory
- If you have issues opening or loading things, you can try to increase the number of GPUs or GBs to see if that helps the speed

3. Once in the MATLAB session:
- Add a path to access the program SPM: addpath /'work/mindlab/Programs/spm12'/
- To open SPM, type: spm fmri; it may take a moment for the program to open

4. 4D to 3D
- Once SPM has opened, open the batch editor
- In the toolbar, open the SPM folder --> Util. --> 4D to 3D File Conversion
- Load 2 seperate 4D to 3D File Conversions for each task condition
- Specify the 4D Volume for each conversion (double click)
	- Ensure the directory is /work/mindlab/NUBIC/THAMP_Study/BIDS/derivatives/fmriprep
	- For each participant, open their func folder within the /work/mindlab/NUBIC/THAMP_Study/BIDS/derivatives/fmriprep directory
	- For SART, choose the file titled "sub-YYMMDDFLLL task-thampsart space-MNI152NLin2009cAsym_desc-preproc_bold.nii"
	- For 2-back, choose the file titled "sub-YYMMDDFLLL task-thamp2back space-MNI152NLin2009cAsym_desc-preproc_bold.nii"
- Before running this, make sure to put the output directory as /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/task (meaning you save the SART 4D to 3D conversion in the slices/SART folder and the 2-back 4D to 3D converstion in the slices/WM folder)
- If the 4D volume matches correct file for the correct participant and the output directory is for the correct slices folder for the correct participant, you can now run this batch editor

5. Realigning
- After the 4D to 3D conversion has completed, open another batch editor
- In the toolbar, open the SPM folder --> Spatial --> Realign --> Realign: Estimate and Reslice
- Double click the "Data" tab to add a session
- Then, add another session so there are 2 in total
- In the first session, add all of the files in the /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/SART folder
	- To select all files, right click the folder, and click "select all"
- Then, in the second session, add all of the files in the /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/WM folder
- Both sessions should individually have 768 files included in the session
	- If for some reason there are not 768 files, you can try to re-do the 4D to 3D conversion or you can run that participant through the fMRIprep pipeline again
- Keep all other estimation options the same (ex. Quality = 0.9, Separation = 4, Smoothing = 5)

6. Smoothing
- Once the realigning step is complete and ready to run, in the toolbar, open the SPM folder --> Spatial --> Smooth
- When choosing the images to smooth, click the bottom right button that says "Dependency"
- After clicking Dependency, choose the RESLICED images from both session 1 (SART) and session 2 (WM)
- Once the correct images have been selected to smooth, you may run the realigning and smoothing batch editor
- Please note that each task will have all 768 images realigned and then smoothed, all saved into the /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/task folder
	- This means that each task folder will have 768 original 4D to 3D slices, 768 realigned images, and 768 realigned and smoothed images
	- For the 1st and 2nd level analysis, we will use the realigned and smoothed images; all of these files MUST begin with srsub not rsub or sub


7. 1st Level Analysis
- Once the data has been sliced, realigned, and smoothed, it is now time to put this through the 1st level analysis!
1. fMRI Model Specification
- To determine how to set-up each participant's 1st level analysis, check the runlog to see if they listened to the modulated or unmodulated music first
	- There are seperate Matlab files on the GitHub labled "modfirst.mat" and "unmodfirst.mat" for this purpose
	- Each session in the fMRI model specification (SART & 2-back) will have 2 conditions (mod & unmod)
	- If the participant receieved modulated music first: the onset of the mod condition would be 1 and the duration would be 384 while the onset of the unmod condition would be 365 and the duration would be 384
	- If the participant receieved unmodulated music first: the onset of the mod condition would be 385 and the duration would be 384 while the onset of the unmod condition would be 1 and the duration would be 384
	- Whatever music condition was recieved first will be true for both sessions (i.e. if you got mod first for the SART task, you will also get mod first for the 2-back task)
- Once the proper matlab file has been loaded into the SPM session, update the directory to /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/spm
	- This is where the 1st level analysis SPM.mat file will save
	- This folder will also contain any and all contrasts, images, or anything else created by the 1st level analysis
- Despite the first music condition there are some consistent variables (ex. Units for Design = Scans, Interscan Interval = 0.475, Microtime Resolution - 16, Microtime Onset = 8)
- Then, in Data & Design, in the 1st session, upload the participants SART files from the /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/SART folder
	- Regardless which task was completed first, ALWAYS include SART a the first session and 2-back as the second session (this will make all con_001 files = SART m>u regardless of task presentation, making 2nd level analysis much more simple)
	- Make sure to ONLY select the srsub files and to select them in sequential order
		- To help with this, type "srsub*" into the Filter textbox
		- This will only show the realigned and smoothed files
		- Then, right click the list to choose "select all"
		- This will ensure that all 768 srsub files are uploaded in the correct order
- Once the SART session files have been uploaded, upload the participants 2-back files from the /work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/slices/WM folder
	- As mentioned before, regardless which task was completed first, ALWAYS include SART a the first session and 2-back as the second session
	- Also mentioned before, make sure to ONLY select the srsub files and to select them in sequential order
- Once all SART and 2-back files have been properly uploaded into each session with the proper conditions and onset times, the rest of the 1st level analysis may be done

2. Model Estimation
- This module will determine the best way to model the images
- For the "Select SPM.mat" section, click the "Dependency" button on the bottom right and make this dependent on fMRI Model Specification: SPM.mat file
- This will estimate the model for the SPM.mat that is being output by the previous module

3. Contrast Manager
- Finally, this will determine the contrasts for the data
- In this case, we will only use T-contasts
- For the "Select SPM.mat" section, click the "Dependency" button on the bottom right and make this dependent on Model Estimation: SPM.mat file
- This will determine contrasts for the SPM.mat that is being output by the previous 2 modules
- There are 3 contrasts already in the matlab files
	1. SART mod>unmod [1 -1 0 0]
	2. 2-back mod>unmod [0 0 1 -1]
	3. SART>2-back [1 1 -1 -1]
- Once these contrasts are set up, the entire 1st level analysis (model specification, model estimation, contrast manager) can be run!

4. Viewing the Data
- In SPM, click the "Results" tab
- Then, upload the SPM.mat file that is in the participant's SPM folder (/work/mindlab/Projects/THAMP/fMRIprepped/YYMMDDFLLL_1lvl/spm)
- Once selected, the 3 main contrasts should come up and more contrasts can be added
		con_0004 = mod>unmod [1 -1 1 -1]
		con_0005 = mod [1 0 1 0]
		con_0006 = unmod [0 1 0 1]
		con_0007 = unmod>mod [-1 1 -1 1]
		con_0008 = 2-back>SART [-1 -1 1 1]
- Right click/select whichever contrast you would like to view first
- For the "apply masking" choice select no
- P Value adjustment can be made to 0.05 or 0.001 (unc) - 0.05 is the signifigance threshold, data should be passing this on the individual level
- Extent threshold can be kept at 0
- Now you can visualize this participant's brain data! To see it relating to an fMRI brain image you can overlay an existing template
	- In the Display section of the results tab, click Overlay --> sections
	- Put the directory as /work/mindlab/Programs/spm12/canonical
	- Choose the single sub TI.nii file
	- Now, you can visualize the participant's data with a canonical brain image

## 2nd Level Analysis





